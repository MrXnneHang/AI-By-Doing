{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d40c2a6-607d-4436-a122-106eab62662c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 强化学习与监督学习的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72c6f7-d8de-481f-8bc2-fc13b85e4480",
   "metadata": {},
   "source": [
    "* 如果按照监督学习的方式，类似于大人会给小孩说，这样做是对的，那样做是错误的。然后，小孩就能知道怎样做是对的，怎样是错误的了。这个过程并不存在奖励机制，无法从环境中获得回报。\n",
    "* 如果按照强化学习的方式，类似于大人什么都不告诉小孩，当小孩说脏话时就会挨打（负奖励），小孩做正确的事情时就给一颗糖吃（正奖励）。最后，小孩也就建立起是非观念了。为了得到更多的糖吃，小孩就会尽量避免做错误的事情。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925afdc0-0577-43d2-8ee2-98c08b575815",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 分类:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2610687-cad4-4bb8-89f6-4f5398441e7c",
   "metadata": {},
   "source": [
    "Q-learning\n",
    "\n",
    "SARSA\n",
    "\n",
    "DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995d6be-bc1f-4b48-a412-f9478194d0c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 组件:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4936a-66bf-436a-b73b-ba9800e71b95",
   "metadata": {},
   "source": [
    "### Policy 策略函数:\n",
    "\n",
    "当前状态作为输入，下一步行动决策作为输出。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec49d3-854a-418c-b999-43b4cc6aa04a",
   "metadata": {},
   "source": [
    "### Value Function:\n",
    "\n",
    "衡量当前状态或者行为的好坏，奖励和惩罚的函数。通常是一个value。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eeb880-92d1-450d-81c3-8963a812e16c",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "智能体(Agent)感知周围环境变化的模式。<br>\n",
    "\n",
    "Agent并不是必须，比如Q-Learning就是不需要智能体的。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965537a-c012-475d-8b4f-131efe6bd773",
   "metadata": {},
   "source": [
    "## 此次强化学习的全部课程集中关注于时间差分学习的部分，并着重于 Q-learning、Sarsa 以及 Policy Gradient 三种最基础的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493517b-7f2b-4b29-9694-3b489debdd83",
   "metadata": {},
   "source": [
    "## !!只是基础!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5314bf1-28c7-4b14-bc63-258e3535fdfd",
   "metadata": {},
   "source": [
    "# Q-Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa81b2-37bd-4a53-bb59-813e9a10ec7e",
   "metadata": {},
   "source": [
    "![](https://cdn.aibydoing.com/aibydoing/images/document-uid214893labid6102timestamp1531891479974.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83a820-296b-4555-97c6-eb85307be380",
   "metadata": {},
   "source": [
    "* 我们不希望狮子碰到地雷，希望他吃到火腿。\n",
    "* 我们希望路径最短。\n",
    "\n",
    "很容易可以看出来，需要5步。并且所有可能性都是有限的。<br>\n",
    "如果是编程，可以挖掉地雷的位置，然后做最短路径问题。<br>\n",
    "但是我们希望这种游戏是可以重复性游玩的，比如每次游玩的时候，变换地雷和火腿的相对位置，保持狮子的位置不变。目的始终是吃火腿，躲地雷，那么这样才有意思。当然，我不知道能不能做到，因为这种情况，似乎传统编程的难度相当大，而且是编程者来硬解。我们希望是由model自己来学习这个模式。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9bbf90f-a41b-4860-876c-3b04debc1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L _ _ _ \n",
      "_ _ _ _ \n",
      "_ # _ _ \n",
      "_ _ $ _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display  # 引入 display 模块目的方便程序运行展示\n",
    "\n",
    "\n",
    "def init_env():\n",
    "    start = (0, 0)\n",
    "    terminal = (3, 2)\n",
    "    hole = (2, 1)\n",
    "    env = np.array([[\"_ \"] * 4] * 4)  # 建立一个 4*4 的环境\n",
    "    env[terminal] = \"$ \"  # 目的地\n",
    "    env[hole] = \"# \"  # 陷阱\n",
    "    env[start] = \"L \"  # 小狮子\n",
    "    interaction = \"\"\n",
    "    for i in env:\n",
    "        interaction += \"\".join(i) + \"\\n\"\n",
    "    print(interaction)\n",
    "\n",
    "\n",
    "init_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc39eb81-063f-4b89-92cb-421930a605fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     up  down  left  right\n",
       "0   0.0   0.0   0.0    0.0\n",
       "1   0.0   0.0   0.0    0.0\n",
       "2   0.0   0.0   0.0    0.0\n",
       "3   0.0   0.0   0.0    0.0\n",
       "4   0.0   0.0   0.0    0.0\n",
       "5   0.0   0.0   0.0    0.0\n",
       "6   0.0   0.0   0.0    0.0\n",
       "7   0.0   0.0   0.0    0.0\n",
       "8   0.0   0.0   0.0    0.0\n",
       "9   0.0   0.0   0.0    0.0\n",
       "10  0.0   0.0   0.0    0.0\n",
       "11  0.0   0.0   0.0    0.0\n",
       "12  0.0   0.0   0.0    0.0\n",
       "13  0.0   0.0   0.0    0.0\n",
       "14  0.0   0.0   0.0    0.0\n",
       "15  0.0   0.0   0.0    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_q_table():\n",
    "    # Q-Table 初始化\n",
    "    actions = np.array([\"up\", \"down\", \"left\", \"right\"])\n",
    "    q_table = pd.DataFrame(\n",
    "        np.zeros((16, len(actions))), columns=actions\n",
    "    )  # 初始化 Q-Table 全为 0\n",
    "    return q_table\n",
    "\n",
    "\n",
    "init_q_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc05f6f-2277-45ac-ac44-8f4f10028fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_choose(state, q_table, epsilon):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    state -- 状态\n",
    "    q_table -- Q-Table\n",
    "    epsilon -- 概率值\n",
    "\n",
    "    返回:\n",
    "    action --下一步动作\n",
    "    \"\"\"\n",
    "    state_act = q_table.iloc[state, :]\n",
    "    actions = np.array([\"up\", \"down\", \"left\", \"right\"])\n",
    "\n",
    "    if np.random.uniform() > epsilon or state_act.all() == 0:\n",
    "        action = np.random.choice(actions)\n",
    "    else:\n",
    "        action = state_act.idxmax()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a4dcf9-2d9e-46a4-ac4b-0704fa3820d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_feedback(state, action, hole, terminal):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    state -- 状态\n",
    "    action -- 动作\n",
    "    hole -- 陷阱位置\n",
    "    terminal -- 终点位置\n",
    "\n",
    "    返回:\n",
    "    next_state -- 下一状态\n",
    "    reward -- 奖励\n",
    "    end --结束标签\n",
    "    \"\"\"\n",
    "    # 行为反馈\n",
    "    reward = 0.0\n",
    "    end = 0\n",
    "    a, b = state\n",
    "    if action == \"up\":\n",
    "        a -= 1\n",
    "        if a < 0:\n",
    "            a = 0\n",
    "        next_state = (a, b)\n",
    "    elif action == \"down\":\n",
    "        a += 1\n",
    "        if a >= 4:\n",
    "            a = 3\n",
    "        next_state = (a, b)\n",
    "    elif action == \"left\":\n",
    "        b -= 1\n",
    "        if b < 0:\n",
    "            b = 0\n",
    "        next_state = (a, b)\n",
    "    elif action == \"right\":\n",
    "        b += 1\n",
    "        if b >= 4:\n",
    "            b = 3\n",
    "        next_state = (a, b)\n",
    "\n",
    "    if next_state == terminal:\n",
    "        reward = 10.0\n",
    "        end = 2\n",
    "    elif next_state == hole:\n",
    "        reward = -10.0\n",
    "        end = 1\n",
    "    else:\n",
    "        reward = -1.0\n",
    "    return next_state, reward, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0eb8e2a-6da2-47ab-816b-1a37c5bdc9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(q_table, state, action, next_state, terminal, gamma, alpha, reward):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    q_table -- Q-Table\n",
    "    state -- 状态\n",
    "    action -- 动作\n",
    "    next_state -- 下一状态\n",
    "    terminal -- 终点位置\n",
    "    gamma -- 折损因子\n",
    "    alpha -- 学习率\n",
    "    reward -- 奖励\n",
    "\n",
    "    返回:\n",
    "    q_table -- 更新后的Q-Table\n",
    "    \"\"\"\n",
    "    # Q-Table 的更新函数\n",
    "    x, y = state\n",
    "    next_x, next_y = next_state\n",
    "    q_original = q_table.loc[x * 4 + y, action]\n",
    "    if next_state != terminal:\n",
    "        q_predict = reward + gamma * q_table.iloc[next_x * 4 + next_y].max()\n",
    "    else:\n",
    "        q_predict = reward\n",
    "    q_table.loc[x * 4 + y, action] = (1 - alpha) * q_original + alpha * q_predict\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf838e6-d4e0-4114-944b-c1787c84eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(end, state, episode, step, q_table):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    end -- 结束标签\n",
    "    state -- 状态\n",
    "    episode -- 迭代次数\n",
    "    step --迭代步数\n",
    "    q_table-- Q-Table\n",
    "    \"\"\"\n",
    "    # 状态可视化辅助函数\n",
    "    terminal = (3, 2)\n",
    "    hole = (2, 1)\n",
    "    env = np.array([[\"_ \"] * 4] * 4)\n",
    "    env[terminal] = \"$ \"\n",
    "    env[hole] = \"# \"\n",
    "    env[state] = \"L \"\n",
    "    interaction = \"\"\n",
    "    for i in env:\n",
    "        interaction += \"\".join(i) + \"\\n\"\n",
    "\n",
    "    if state == terminal:\n",
    "        message = \"EPISODE: {}, STEP: {}\".format(episode, step)\n",
    "        interaction += message\n",
    "        display.clear_output(wait=True)  # 清除输出内容\n",
    "        print(interaction)\n",
    "        print(\"\\n\" + \"q_table:\")\n",
    "        print(q_table)\n",
    "        time.sleep(3)  # 在成功到终点时，等待 3 秒\n",
    "    else:\n",
    "        display.clear_output(wait=True)\n",
    "        print(interaction)\n",
    "        print(q_table)\n",
    "        time.sleep(0.3)  # 在这里控制每走一步所需要时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e78bf7d-1e61-480d-8688-ae171342319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(max_episodes, alpha, gamma, epsilon):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    max_episodes -- 最大迭代次数\n",
    "    alpha -- 学习率\n",
    "    gamma -- 折损因子\n",
    "    epsilon -- 概率值\n",
    "\n",
    "    返回:\n",
    "    q_table -- 更新后的Q-Table\n",
    "    \"\"\"\n",
    "    q_table = init_q_table()\n",
    "    terminal = (3, 2)\n",
    "    hole = (2, 1)\n",
    "    episodes = 0\n",
    "    while episodes <= max_episodes:\n",
    "        step = 0\n",
    "        state = (0, 0)\n",
    "        end = 0\n",
    "        show_state(end, state, episodes, step, q_table)\n",
    "        while end == 0:\n",
    "            x, y = state\n",
    "            act = act_choose(x * 4 + y, q_table, epsilon)  # 动作选择\n",
    "            next_state, reward, end = env_feedback(state, act, hole, terminal)  # 环境反馈\n",
    "            q_table = update_q_table(\n",
    "                q_table, state, act, next_state, terminal, gamma, alpha, reward\n",
    "            )  # q-table 更新\n",
    "            state = next_state\n",
    "            step += 1\n",
    "            show_state(end, state, episodes, step, q_table)\n",
    "        if end == 2:\n",
    "            episodes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d62fdba-932a-43a4-8b9c-afe146b52905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ \n",
      "_ _ _ _ \n",
      "_ # _ _ \n",
      "_ _ L _ \n",
      "EPISODE: 60, STEP: 5\n",
      "\n",
      "q_table:\n",
      "           up      down      left      right\n",
      "0   -3.368121  3.122000  1.605217  -3.349864\n",
      "1   -3.112465 -2.656223 -3.146730   0.894333\n",
      "2   -2.213120  5.069215 -2.916351  -1.857024\n",
      "3   -1.718528 -0.999936 -0.999680  -1.536000\n",
      "4    0.907711  4.580000  2.878692   0.300440\n",
      "5   -2.475887 -8.000000 -2.271360   5.100961\n",
      "6   -0.999936  7.856577 -1.651200  -0.998400\n",
      "7   -1.891973  2.464000 -0.960000   0.000000\n",
      "8   -2.780328  6.200000  4.525414  -9.999872\n",
      "9    0.000000  0.000000  0.000000   0.000000\n",
      "10  -1.651200  9.984000 -9.920000   2.771200\n",
      "11   0.000000  7.072000  4.960000   2.611200\n",
      "12   4.531180  6.187589 -1.683200   8.000000\n",
      "13 -10.000000  7.999205  5.951967  10.000000\n",
      "14   0.000000  0.000000  0.000000   0.000000\n",
      "15   0.000000  5.952000  9.920000   0.000000\n"
     ]
    }
   ],
   "source": [
    "q_learning(max_episodes=60, alpha=0.8, gamma=0.9, epsilon=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d98049-98f4-4326-b58b-6af92efb0302",
   "metadata": {},
   "source": [
    "到了最后，我的狮子都是下下下右右,这种Q-Table的实际上在找最优有点死板。<br>\n",
    "\n",
    "它把所有位置的所有可能都列出来，存储量还是很大的，如果下五子棋也这么搞，也就是要记录所有的残局情况。<br>\n",
    "\n",
    "然后一次次解出残局的最优解。<br>\n",
    "\n",
    "用数学函数来说，实际上就是不断修正函数，来让函数来拟合某一个最优解。<br>\n",
    "\n",
    "有缺点，这里，每次更换目标都需要重新训练，而且每一次都不能找出所有最优解，只是找出一个局部最优解。【实际上这点也有点为难人了。】<br>\n",
    "\n",
    "但是，实际上，这个应该在五子棋上面表现不错。只是参数量估计相当大。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50aba8-4402-42af-85ef-52cf5ee1f505",
   "metadata": {},
   "source": [
    "## 让游戏更有意思一些。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d43ca-f3ef-410d-b695-8fd0c190b717",
   "metadata": {},
   "source": [
    "我把狮子的出生点随机化了(陷阱和hole除外）<br>\n",
    "\n",
    "实际上没有改动算法根基，如果要动火腿和陷阱，目前的Q-Table就不能是静态的。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5146e8d-b19f-4759-a26d-2276fcdaee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_start_q_learning(max_episodes, alpha, gamma, epsilon):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    max_episodes -- 最大迭代次数\n",
    "    alpha -- 学习率\n",
    "    gamma -- 折损因子\n",
    "    epsilon -- 探索概率值\n",
    "\n",
    "    返回:\n",
    "    q_table -- 更新后的Q-Table\n",
    "    \"\"\"\n",
    "    q_table = init_q_table()\n",
    "    terminal = (3, 2)\n",
    "    hole = (2, 1)\n",
    "    \n",
    "    # 定义网格的所有合法起点，排除 hole 和 terminal\n",
    "    valid_start_positions = [(i, j) for i in range(4) for j in range(4) if (i, j) != hole and (i, j) != terminal]\n",
    "\n",
    "    episodes = 0\n",
    "    while episodes <= max_episodes:\n",
    "        step = 0\n",
    "\n",
    "        # 随机选择起始点，排除 hole 和 terminal\n",
    "        state = random.choice(valid_start_positions)\n",
    "\n",
    "        end = 0\n",
    "        show_state(end, state, episodes, step, q_table)\n",
    "        while end == 0:\n",
    "            x, y = state\n",
    "            act = act_choose(x * 4 + y, q_table, epsilon)  # 动作选择\n",
    "            next_state, reward, end = env_feedback(state, act, hole, terminal)  # 环境反馈\n",
    "            q_table = update_q_table(\n",
    "                q_table, state, act, next_state, terminal, gamma, alpha, reward\n",
    "            )  # q-table 更新\n",
    "            state = next_state\n",
    "            step += 1\n",
    "            show_state(end, state, episodes, step, q_table)\n",
    "        if end == 2:\n",
    "            episodes += 1\n",
    "\n",
    "    return q_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f775450-c2e7-48ee-b516-597cb5b8ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ \n",
      "_ _ _ _ \n",
      "_ # _ _ \n",
      "_ _ L _ \n",
      "EPISODE: 60, STEP: 5\n",
      "\n",
      "q_table:\n",
      "          up       down      left     right\n",
      "0  -1.683200  -1.798400 -1.683200  3.120820\n",
      "1   2.153950   4.579999 -1.804800  3.465572\n",
      "2  -0.960000   6.199998 -1.683200 -1.821440\n",
      "3  -1.536000  -0.998400  4.569193 -1.683200\n",
      "4  -1.376000  -1.536000 -1.536000  4.580000\n",
      "5   3.064217  -9.600000  2.265684  6.200000\n",
      "6   3.886458   8.000000  3.504000  2.468968\n",
      "7   2.742232   4.656794  5.912491  2.628968\n",
      "8   3.114336  -1.711770 -2.213120 -8.000000\n",
      "9   0.000000   0.000000  0.000000  0.000000\n",
      "10  6.143953  10.000000 -8.000000  2.771200\n",
      "11  2.628968   7.982234  7.532800  5.581517\n",
      "12 -2.213120  -1.821440 -1.712640  4.760013\n",
      "13 -9.920000  -0.999680 -1.717248  9.999360\n",
      "14  0.000000   0.000000  0.000000  0.000000\n",
      "15  3.485440   4.960000  9.999872 -0.800000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.683200</td>\n",
       "      <td>-1.798400</td>\n",
       "      <td>-1.683200</td>\n",
       "      <td>3.120820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.153950</td>\n",
       "      <td>4.579999</td>\n",
       "      <td>-1.804800</td>\n",
       "      <td>3.465572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.960000</td>\n",
       "      <td>6.199998</td>\n",
       "      <td>-1.683200</td>\n",
       "      <td>-1.821440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.536000</td>\n",
       "      <td>-0.998400</td>\n",
       "      <td>4.569193</td>\n",
       "      <td>-1.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.376000</td>\n",
       "      <td>-1.536000</td>\n",
       "      <td>-1.536000</td>\n",
       "      <td>4.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.064217</td>\n",
       "      <td>-9.600000</td>\n",
       "      <td>2.265684</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.886458</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.504000</td>\n",
       "      <td>2.468968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.742232</td>\n",
       "      <td>4.656794</td>\n",
       "      <td>5.912491</td>\n",
       "      <td>2.628968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.114336</td>\n",
       "      <td>-1.711770</td>\n",
       "      <td>-2.213120</td>\n",
       "      <td>-8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.143953</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>2.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.628968</td>\n",
       "      <td>7.982234</td>\n",
       "      <td>7.532800</td>\n",
       "      <td>5.581517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.213120</td>\n",
       "      <td>-1.821440</td>\n",
       "      <td>-1.712640</td>\n",
       "      <td>4.760013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-9.920000</td>\n",
       "      <td>-0.999680</td>\n",
       "      <td>-1.717248</td>\n",
       "      <td>9.999360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.485440</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>9.999872</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          up       down      left     right\n",
       "0  -1.683200  -1.798400 -1.683200  3.120820\n",
       "1   2.153950   4.579999 -1.804800  3.465572\n",
       "2  -0.960000   6.199998 -1.683200 -1.821440\n",
       "3  -1.536000  -0.998400  4.569193 -1.683200\n",
       "4  -1.376000  -1.536000 -1.536000  4.580000\n",
       "5   3.064217  -9.600000  2.265684  6.200000\n",
       "6   3.886458   8.000000  3.504000  2.468968\n",
       "7   2.742232   4.656794  5.912491  2.628968\n",
       "8   3.114336  -1.711770 -2.213120 -8.000000\n",
       "9   0.000000   0.000000  0.000000  0.000000\n",
       "10  6.143953  10.000000 -8.000000  2.771200\n",
       "11  2.628968   7.982234  7.532800  5.581517\n",
       "12 -2.213120  -1.821440 -1.712640  4.760013\n",
       "13 -9.920000  -0.999680 -1.717248  9.999360\n",
       "14  0.000000   0.000000  0.000000  0.000000\n",
       "15  3.485440   4.960000  9.999872 -0.800000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_start_q_learning(max_episodes=60, alpha=0.8, gamma=0.9, epsilon=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924dab2-5b16-4d29-a20e-dd4f68ac433f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
