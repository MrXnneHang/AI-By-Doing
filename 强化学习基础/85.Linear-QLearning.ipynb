{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb17090-5ed8-42c1-b5bb-8f7d081bc394",
   "metadata": {},
   "source": [
    "## Q-LearningÂ  \n",
    "### è®¡ç®—æ­¥éª¤ï¼š\n",
    "\n",
    "1. Q-Tableçš„åˆ›å»ºï¼š æƒ³è±¡ä¸€ä¸ªè¡¨æ ¼ï¼Œè¡Œæ˜¯å°ç‹®å­çš„ä½ç½®ï¼Œåˆ—æ˜¯å®ƒå¯ä»¥é‡‡å–çš„åŠ¨ä½œï¼ˆæ¯”å¦‚ä¸Šã€ä¸‹ã€å·¦ã€å³ï¼‰ã€‚æ¯ä¸ªå•å…ƒæ ¼çš„å€¼å«Qå€¼ï¼Œä»£è¡¨åœ¨è¿™ä¸ªä½ç½®é‡‡å–è¿™ä¸ªåŠ¨ä½œçš„â€œå¥½åâ€ã€‚\n",
    "2. æ›´æ–°Qå€¼ï¼š\n",
    "\n",
    "* å°ç‹®å­é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®ã€‚\n",
    "* å¾—åˆ°å¥–åŠ±ï¼ˆå¦‚æœæ‰¾åˆ°ç«è…¿ï¼ŒåŠ åˆ†ï¼›ç¢°åˆ°é™·é˜±ï¼Œå‡åˆ†ï¼‰ã€‚\n",
    "* æ›´æ–°å…¬å¼æ˜¯ï¼š\n",
    "  æ–°çš„Qå€¼=æ—§çš„Qå€¼+å­¦ä¹ ç‡Ã—(å¥–åŠ±+æœªæ¥æœ€å¤§Qå€¼âˆ’æ—§çš„Qå€¼)\n",
    "* å­¦ä¹ ç‡å†³å®šäº†è¿™æ¬¡æ›´æ–°å¯¹æ—§å€¼çš„å½±å“æœ‰å¤šå¤§ã€‚\n",
    "## Linear Q-Learning\n",
    "### è®¡ç®—æ­¥éª¤ï¼š\n",
    "\n",
    "1. ç‰¹å¾å‘é‡ï¼š è¿™é‡Œä¸å†ç”¨è¡¨æ ¼ï¼Œè€Œæ˜¯ç”¨ä¸€ä¸ªç®€å•çš„æ•°å­¦å…¬å¼æ¥è¡¨ç¤ºQå€¼ã€‚æƒ³è±¡å°ç‹®å­çš„çŠ¶æ€ï¼ˆä½ç½®ï¼‰ç”¨å‡ ä¸ªæ•°å­—æ¥æè¿°ã€‚\n",
    "2. æ›´æ–°æƒé‡ï¼š\n",
    "\n",
    "* ä½¿ç”¨ç‰¹å¾å‘é‡æ¥è®¡ç®—Qå€¼ã€‚\n",
    "* æ›´æ–°æƒé‡çš„æ–¹å¼ç±»ä¼¼ï¼š\n",
    "  æ–°çš„æƒé‡=æ—§çš„æƒé‡+å­¦ä¹ ç‡Ã—(å¥–åŠ±+æœªæ¥æœ€å¤§Qå€¼âˆ’å½“å‰Qå€¼)Ã—ç‰¹å¾å‘é‡\n",
    "\n",
    "* è¿™é‡Œçš„â€œç‰¹å¾å‘é‡â€å°±åƒæ˜¯æè¿°å°ç‹®å­å½“å‰çŠ¶æ€çš„æ•°å­—ç»„åˆã€‚\n",
    "## åŒºåˆ«æ€»ç»“\n",
    "1. Q-Learningï¼š ä½¿ç”¨è¡¨æ ¼é€ä¸ªè®°å½•æ¯ä¸ªçŠ¶æ€å’ŒåŠ¨ä½œçš„Qå€¼ï¼Œæ¯æ¬¡æ›´æ–°ä¸€ä¸ªå•å…ƒæ ¼ã€‚\n",
    "2. Linear Q-Learningï¼š ä¸ç”¨è¡¨æ ¼ï¼Œè€Œæ˜¯ç”¨å…¬å¼å’Œæ•°å­—ç»„åˆæ¥å¿«é€Ÿä¼°ç®—Qå€¼ï¼Œæ¯æ¬¡è°ƒæ•´å…¬å¼çš„å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ff006-6d1f-49a1-9d96-2d7ebce7d3f2",
   "metadata": {},
   "source": [
    "## è¯¦è§£ç‰¹å¾å‘é‡å’Œæƒé‡å‘é‡ï¼š\n",
    "\n",
    "Ï•(s)=[x,y,d]<br>\n",
    "\n",
    "x,yåæ ‡ï¼Œdæ˜¯è·ç¦»ç«è…¿çš„è·ç¦»ï¼Œå®é™…ä¸Šä¹Ÿå¯ä»¥d,dï¼Œä¸¤ä¸ªè·ç¦»éƒ½æ”¾è¿›æ¥ã€‚<br>\n",
    "\n",
    "### æƒé‡å‘é‡å’Œç‰¹å¾å‘é‡:<br>\n",
    "\n",
    "1. ç‰¹å¾å‘é‡ï¼š ä»£è¡¨å½“å‰çŠ¶æ€çš„ç‰¹å¾ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œå¦‚:<br>\n",
    "\n",
    "Ï•(s)=[a,b,c,d...]ã€‚<br>\n",
    "\n",
    "2. æƒé‡å‘é‡ï¼š å­˜å‚¨ä¸ç‰¹å¾ç›¸å…³çš„æƒé‡ï¼Œå½¢çŠ¶ä¸ç‰¹å¾å‘é‡ç›¸åŒï¼Œå¦‚ \n",
    "ğœƒ=[a1,b1,c1,d1...]ã€‚<br>\n",
    "\n",
    "æƒé‡å‘é‡å°±æ˜¯Q-Tableçš„Q-value,ç‰¹å¾å‘é‡å°±æ˜¯Q-Table,ä¸è¿‡ï¼Œç‰¹å¾å‘é‡å’Œæƒé‡å‘é‡åšäº†æ›´ç²¾ç»†çš„ç»´åº¦åˆ†è§£ï¼Œx,yéƒ½æœ‰q-value,è¿˜æœ‰d,è€Œä¸æ˜¯one-hotäº†ã€‚<br>\n",
    "\n",
    "ç‰¹å¾æ›´å¤æ‚ï¼Œç»´åº¦æ›´é«˜çš„æƒ…å†µä¸‹ï¼ŒQ-Tableä¼šæŠ¥åºŸï¼Œè€ŒLinear-Qlearningä¼šæ›´èƒ½ç«™ä¸€äº›ã€‚<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7bdc51-3d8a-4092-b5dc-5590b8f0554b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# è®¾ç½®åœ°å›¾å’Œç›¸å…³å‚æ•°\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# è®¾ç½®åœ°å›¾å’Œç›¸å…³å‚æ•°\n",
    "grid_size = 5\n",
    "num_episodes = 10\n",
    "max_steps = 20\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "exploration_rate = 1.0\n",
    "exploration_decay = 0.99\n",
    "\n",
    "# åˆå§‹åŒ–Q-Table\n",
    "q_table = np.zeros((grid_size, grid_size, 4))  # 4ä¸ªåŠ¨ä½œï¼šä¸Šã€ä¸‹ã€å·¦ã€å³\n",
    "\n",
    "# å®šä¹‰åŠ¨ä½œ\n",
    "UP, DOWN, LEFT, RIGHT = 0, 1, 2, 3\n",
    "\n",
    "# å®šä¹‰ç¯å¢ƒçŠ¶æ€\n",
    "fire_position = (3, 2)\n",
    "trap_position = (2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b3f04-7f28-451d-b95b-140c8c8a5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_position(state, action):\n",
    "    x, y = state\n",
    "    if action == UP:\n",
    "        return (max(0, x - 1), y)\n",
    "    elif action == DOWN:\n",
    "        return (min(grid_size - 1, x + 1), y)\n",
    "    elif action == LEFT:\n",
    "        return (x, max(0, y - 1))\n",
    "    elif action == RIGHT:\n",
    "        return (x, min(grid_size - 1, y + 1))\n",
    "\n",
    "def get_reward(state):\n",
    "    if state == fire_position:\n",
    "        return 10  # æ‰¾åˆ°ç«è…¿\n",
    "    elif state == trap_position:\n",
    "        return -10  # ç¢°åˆ°é™·é˜±\n",
    "    else:\n",
    "        return -1  # æ¯ä¸€æ­¥çš„æƒ©ç½š\n",
    "\n",
    "def show_state(end, state, episode, step, q_table):\n",
    "    terminal = fire_position\n",
    "    hole = trap_position\n",
    "    env = np.array([[\"_ \"] * grid_size for _ in range(grid_size)])\n",
    "    env[terminal] = \"$ \"\n",
    "    env[hole] = \"# \"\n",
    "    env[state] = \"L \"\n",
    "    interaction = \"\"\n",
    "    for row in env:\n",
    "        interaction += \"\".join(row) + \"\\n\"\n",
    "\n",
    "    if state == terminal:\n",
    "        message = \"EPISODE: {}, STEP: {}\".format(episode, step)\n",
    "        interaction += message\n",
    "        display.clear_output(wait=True)\n",
    "        print(interaction)\n",
    "        print(\"\\n\" + \"q_table:\")\n",
    "        print(q_table)\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        display.clear_output(wait=True)\n",
    "        print(interaction)\n",
    "        print(q_table)\n",
    "        time.sleep(0.3)\n",
    "\n",
    "# è®­ç»ƒè¿‡ç¨‹\n",
    "for episode in range(num_episodes):\n",
    "    state = (0, 0)  # åˆå§‹åŒ–ä½ç½®\n",
    "    for step in range(max_steps):\n",
    "        # é€‰æ‹©åŠ¨ä½œ\n",
    "        if random.uniform(0, 1) < exploration_rate:\n",
    "            action = random.randint(0, 3)  # éšæœºé€‰æ‹©åŠ¨ä½œ\n",
    "        else:\n",
    "            action = np.argmax(q_table[state[0], state[1]])  # é€‰æ‹©Qå€¼æœ€é«˜çš„åŠ¨ä½œ\n",
    "\n",
    "        next_state = get_next_position(state, action)\n",
    "        reward = get_reward(next_state)\n",
    "\n",
    "        # Q-Learningæ›´æ–°\n",
    "        q_table[state[0], state[1], action] += learning_rate * (\n",
    "            reward + discount_factor * np.max(q_table[next_state[0], next_state[1]]) - q_table[state[0], state[1], action]\n",
    "        )\n",
    "\n",
    "        # æ›´æ–°çŠ¶æ€\n",
    "        state = next_state\n",
    "\n",
    "        # æ˜¾ç¤ºçŠ¶æ€\n",
    "        show_state(state == fire_position, state, episode, step, q_table)\n",
    "\n",
    "    # é™ä½æ¢ç´¢ç‡\n",
    "    exploration_rate *= exploration_decay\n",
    "\n",
    "# è®­ç»ƒå®Œæˆ\n",
    "print(\"Training finished!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
